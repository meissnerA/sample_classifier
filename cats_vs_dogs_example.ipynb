{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebefc1a9-918b-4cb3-b7a8-6716d9289813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from skimage import io\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac88db8c-54a6-4d4b-aff2-4b3bf575f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_path = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015aa40d-b727-4570-bc9e-d32b92fb0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 loss:  0.747825026512146\n",
      "iteration: 0 train acc: 0.5\n",
      "validation loss:  0.7292786238670349\n",
      "validation acc: 0.4708\n",
      "\n",
      "iteration: 1000 loss:  0.16089071333408356\n",
      "iteration: 1000 train acc: 1.0\n",
      "validation loss:  0.10791223244071006\n",
      "validation acc: 0.9764\n",
      "\n",
      "iteration: 2000 loss:  0.03702716901898384\n",
      "iteration: 2000 train acc: 1.0\n",
      "validation loss:  0.08869834107905626\n",
      "validation acc: 0.978\n",
      "\n",
      "iteration: 0 loss:  0.05647910013794899\n",
      "iteration: 0 train acc: 1.0\n",
      "validation loss:  0.07697942672520876\n",
      "validation acc: 0.9782\n",
      "\n",
      "iteration: 1000 loss:  0.05052806809544563\n",
      "iteration: 1000 train acc: 1.0\n",
      "validation loss:  0.08090505643337965\n",
      "validation acc: 0.9826\n",
      "\n",
      "iteration: 2000 loss:  1.3421473503112793\n",
      "iteration: 2000 train acc: 0.625\n",
      "validation loss:  0.06804681139588356\n",
      "validation acc: 0.9832\n",
      "\n",
      "iteration: 0 loss:  0.013626862317323685\n",
      "iteration: 0 train acc: 1.0\n",
      "validation loss:  0.06514666835963726\n",
      "validation acc: 0.9844\n",
      "\n",
      "iteration: 1000 loss:  0.019855575636029243\n",
      "iteration: 1000 train acc: 1.0\n",
      "validation loss:  0.06415753640681505\n",
      "validation acc: 0.9854\n",
      "\n",
      "iteration: 2000 loss:  0.007031502202153206\n",
      "iteration: 2000 train acc: 1.0\n",
      "validation loss:  0.05275170465409756\n",
      "validation acc: 0.9888\n",
      "\n",
      "iteration: 0 loss:  0.02160494402050972\n",
      "iteration: 0 train acc: 1.0\n",
      "validation loss:  0.07209796608313918\n",
      "validation acc: 0.979\n",
      "\n",
      "iteration: 1000 loss:  0.05717560648918152\n",
      "iteration: 1000 train acc: 1.0\n",
      "validation loss:  0.04514479609057307\n",
      "validation acc: 0.9892\n",
      "\n",
      "iteration: 2000 loss:  0.018190082162618637\n",
      "iteration: 2000 train acc: 1.0\n",
      "validation loss:  0.04641051918268204\n",
      "validation acc: 0.989\n",
      "\n",
      "iteration: 0 loss:  0.005000037141144276\n",
      "iteration: 0 train acc: 1.0\n",
      "validation loss:  0.0430744258068502\n",
      "validation acc: 0.9884\n",
      "\n",
      "iteration: 1000 loss:  0.00915343128144741\n",
      "iteration: 1000 train acc: 1.0\n",
      "validation loss:  0.04835282103121281\n",
      "validation acc: 0.987\n",
      "\n",
      "iteration: 2000 loss:  0.018706094473600388\n",
      "iteration: 2000 train acc: 1.0\n",
      "validation loss:  0.04708765657618642\n",
      "validation acc: 0.9878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "_mean = [0.5, 0.5, 0.5]\n",
    "_std = [0.5, 0.5, 0.5]\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([IMG_SIZE, IMG_SIZE]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std)\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform=transform\n",
    "        self.input_dir = root_dir\n",
    "        self.img_paths = []\n",
    "        \n",
    "        for file_path in self.input_dir.glob(\"train/*.jpg\"):\n",
    "            #file_path = str(self.input_dir.glob) + \"Cat/\" + file_path\n",
    "            self.img_paths.append(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = io.imread(self.img_paths[idx]) \n",
    "        image = torch.from_numpy(image)\n",
    "        label = 0 if \"dog\" in str(self.img_paths[idx]) else 1\n",
    "\n",
    "        if self.transform:\n",
    "            try:\n",
    "                image = image.permute(2, 0, 1)\n",
    "                image = trans(image)\n",
    "            except:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "\n",
    "        return image, torch.Tensor([label])\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "transformed_dataset = ImageDataset(pathlib.Path('./data'), transform=True)\n",
    "train_set, val_set = torch.utils.data.random_split(transformed_dataset, [20000, 5000])\n",
    "train_dataloader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=8, shuffle=True)\n",
    "\n",
    "sigmoid = nn.Sigmoid().to(device)\n",
    "model.train() # set model to training mod\n",
    "for j in range(5):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "        X, y = X.to(device), y.to(device) # data to GPU\n",
    "        y_ = model(X)\n",
    "        y_ = sigmoid(y_)\n",
    "        y_ = y_.reshape(y_.shape[0],1)\n",
    "        loss = criterion(y_, y) \n",
    "        loss.backward(loss)\n",
    "        optimizer.step()\n",
    "        if i%1000 == 0:\n",
    "            print('iteration:', i , 'loss: ', loss.item())\n",
    "            print('iteration:', i, 'train acc:', (y_.round() == y).sum().item()/(y.shape[0]))\n",
    "            # validation loss\n",
    "            loss = 0\n",
    "            acc = 0\n",
    "            for i, batch in enumerate(val_dataloader):\n",
    "                optimizer.zero_grad()\n",
    "                X = batch[0]\n",
    "                y = batch[1]\n",
    "                X, y = X.to(device), y.to(device) # data to GPU\n",
    "\n",
    "                y_ = model(X)\n",
    "                y_ = sigmoid(y_)\n",
    "                y_ = y_.reshape(y_.shape[0],1)\n",
    "                loss += criterion(y_, y).item()\n",
    "                acc += (y_.round() == y).sum().item()/(y.shape[0])\n",
    "            print('validation loss: ', loss/(i+1))\n",
    "            print('validation acc:', acc/(i+1))\n",
    "            print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0ec59-2f89-4fdf-b98c-58981df44b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#saving the model\n",
    "import pickle\n",
    "file_to_store = open(\"resnet_092_all_attr_5_epochs.pkl\", \"wb\")\n",
    "pickle.dump(model, file_to_store)\n",
    "file_to_store.close()\n",
    "\n",
    "# reading the model\n",
    "import pickle\n",
    "\n",
    "file_to_read = open(\"resnet_092_all_attr_5_epochs.pkl\", \"rb\")\n",
    "model = pickle.load(file_to_read).to(device)\n",
    "file_to_read.close()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cats_dogs",
   "language": "python",
   "name": "venv_cats_dogs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
